{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing required python modules\n\nimport os\nimport cv2\nimport csv\nimport math\nimport h5py\nimport glob\nimport scipy\nimport shutil\nimport random\nimport argparse\n\nimport pandas as pd\nimport numpy as np\nimport keras.backend as K\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom scipy.io import loadmat\nfrom numpy import expand_dims\nfrom matplotlib import pyplot\nfrom PIL import Image, ImageOps\nfrom imageio import imwrite, imread\nfrom keras.models import Model, Sequential, load_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Conv2D, MaxPooling2D, Input, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-17T08:24:11.946853Z","iopub.execute_input":"2022-04-17T08:24:11.9472Z","iopub.status.idle":"2022-04-17T08:24:17.543679Z","shell.execute_reply.started":"2022-04-17T08:24:11.947114Z","shell.execute_reply":"2022-04-17T08:24:17.54293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up working directory\n\ndataset_part = 'part_B'\nworking_input_folder = '../working/input/shanghaitech/'\n\n# making the required folders in working directory\nfor i in [working_input_folder]:\n    if not os.path.exists(i):\n        os.makedirs(i)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T20:25:13.976693Z","iopub.execute_input":"2022-04-03T20:25:13.977015Z","iopub.status.idle":"2022-04-03T20:25:13.984787Z","shell.execute_reply.started":"2022-04-03T20:25:13.976978Z","shell.execute_reply":"2022-04-03T20:25:13.984086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy input directory dataset into working directory\n\ndataset_initial_path = '../input/shanghaitech/ShanghaiTech/'\ndataset_copy_path = '../working/input/shanghaitech/ShanghaiTech/'\n\n# copying the dataset directory tree into working directory\nshutil.copytree(dataset_initial_path, dataset_copy_path)\nprint('copying completed')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T20:25:17.41242Z","iopub.execute_input":"2022-04-03T20:25:17.412721Z","iopub.status.idle":"2022-04-03T20:25:33.400768Z","shell.execute_reply.started":"2022-04-03T20:25:17.412678Z","shell.execute_reply":"2022-04-03T20:25:33.399778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of low light and night time images\nmethod_1_night_images_percent = 0.3\nmethod_2_night_images_percent = 0.4\n\n# Number of images or outputs to be displayed\nnumber_of_degraded_images_to_display = 8\nnumber_of_enhanced_images_to_display = 8","metadata":{"execution":{"iopub.status.busy":"2022-04-03T20:25:33.402551Z","iopub.execute_input":"2022-04-03T20:25:33.402861Z","iopub.status.idle":"2022-04-03T20:25:33.407644Z","shell.execute_reply.started":"2022-04-03T20:25:33.402817Z","shell.execute_reply":"2022-04-03T20:25:33.406671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to display original image and corresponding degraded image\ndef display_degraded_image(image_path, original_image, degraded_image):\n    print(image_path)\n    \n    # initializing a subplot of size 1*2\n    f, axarr = plt.subplots(1, 2, figsize=(10,10))\n\n    # assigning images to subplot\n    axarr[0].imshow(original_image)\n    axarr[1].imshow(degraded_image)\n    \n    # removing ticks from both axes\n    axarr[0].set_xticks([])\n    axarr[0].set_yticks([])\n    axarr[1].set_xticks([])\n    axarr[1].set_yticks([])\n    \n    # set plot titles\n    axarr[0].title.set_text('original image')\n    axarr[1].title.set_text('degraded image')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T20:25:33.408986Z","iopub.execute_input":"2022-04-03T20:25:33.409193Z","iopub.status.idle":"2022-04-03T20:25:33.42156Z","shell.execute_reply.started":"2022-04-03T20:25:33.409168Z","shell.execute_reply":"2022-04-03T20:25:33.420771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converts test data to low light and night time images\n\n# Testing images data path\ntest_data_path = dataset_copy_path + dataset_part + '/test_data/images/'\n\n# testing images loaded into memory\nimage_files = [filename for filename in os.listdir(test_data_path)]\nnum_images = len(image_files)\nindices = list(range(1, num_images + 1))\n\n# number of images for both types of degradation\nmethod_1_images = int(num_images * method_1_night_images_percent)\nmethod_2_images = int(num_images * method_2_night_images_percent)\n\n# degradation of images by method-1 to night time images\nfor idx in range(method_1_images):\n    ind = indices[idx]\n    \n    # printing number of images degraded so far\n    if (idx+1) % 10 == 0:\n        print('Processing {}/{} files'.format(idx+1, num_images))\n    \n    # loading images for degradation\n    input_img_name = ''.join((test_data_path, 'IMG_', str(ind), '.jpg'))    \n    img = imread(input_img_name)\n\n    # generating and saving night time images\n    arr = img * np.array([0.2,0.4,0.7])\n    arr2 = (255*arr/arr.max()).astype(np.uint8)\n    imwrite(input_img_name, arr2)\n    \n    # printing degraded night time images\n    if idx < number_of_degraded_images_to_display/2:\n        display_degraded_image(input_img_name, img, arr2)\n    \n    \n# degradation of images by method-2 to low light images\nfor idx in range(method_2_images):\n    ind = indices[idx+method_1_images]\n    \n    # printing number of images degraded so far\n    if (idx+1) % 10 == 0:\n        print('Processing {}/{} files'.format(idx+1, num_images))\n    \n    # loading images for degradation\n    input_img_name = ''.join((test_data_path, 'IMG_', str(ind), '.jpg'))\n    img = load_img(input_img_name)\n    \n    # convert image to numpy array representation\n    data = img_to_array(img)\n    \n    # expand dimension to one sample\n    samples = expand_dims(data, 0)\n    \n    # create image data augmentation generator for degrading brightness level of image\n    datagen = ImageDataGenerator(brightness_range=[0.2,0.7])\n    \n    # prepare iterator, generate and save low light image\n    it = datagen.flow(samples, batch_size=1)\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    imwrite(input_img_name, image)\n\n    # printing degraded low light images\n    if idx < number_of_degraded_images_to_display/2:\n        display_degraded_image(input_img_name, img, image)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T20:25:58.380577Z","iopub.execute_input":"2022-04-03T20:25:58.380931Z","iopub.status.idle":"2022-04-03T20:26:17.883549Z","shell.execute_reply.started":"2022-04-03T20:25:58.380889Z","shell.execute_reply":"2022-04-03T20:26:17.88279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of patches to be taken from each image\nnum_of_patches = 16\n\n# number of images in training dataset\ntrain_dataset_size = 400\n\n# setting paths to dataset directories \ndataset_base_path = dataset_copy_path + dataset_part + '/'\noutput_base_path = '../working/shanghaitech/' + dataset_part + '/'\ntrain_images_path = dataset_base_path + 'train_data/images/'\ntrain_gt_path = dataset_base_path + 'train_data/ground-truth/'\ntrain_gt_den_map_csv_path = output_base_path + 'train_data/ground_truth_den_map_csv/'\n\n# setting path to store patches data\npatches_dataset_path = output_base_path + 'patches_data/'\npatches_path_train_images = patches_dataset_path + 'train_images/'\npatches_path_train_den_map = patches_dataset_path + 'train_den_map/'\npatches_path_val_images = patches_dataset_path + 'val_images/'\npatches_path_val_den_map = patches_dataset_path + 'val_den_map/'\n\n# creating required directories\nfor i in [train_gt_den_map_csv_path, patches_dataset_path, patches_path_train_images, patches_path_train_den_map, patches_path_val_images, patches_path_val_den_map]:\n    if not os.path.exists(i):\n        os.makedirs(i)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.07205Z","iopub.execute_input":"2022-03-29T18:23:14.07243Z","iopub.status.idle":"2022-03-29T18:23:14.081645Z","shell.execute_reply.started":"2022-03-29T18:23:14.072394Z","shell.execute_reply":"2022-03-29T18:23:14.080967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate density map from given annotated people heads using gaussian kernel\n\ndef gen_density_map(img, anno_points):\n    # initializing density map with all zeroes\n    density_map = np.zeros_like(img, dtype=np.float64)\n    h, w = density_map.shape\n    \n    # Gaussian kernel size\n    kernel_size = 15 \n    # standard deviation\n    sigma = 4.0 \n\n    for point in anno_points:\n        # Center point coordinates of human head\n        x, y = min(w-1, abs(math.floor(point[0]))), min(h-1, abs(math.floor(point[1])))\n\n        # Upper left corner coordinates and lower right corner coordinates\n        x1, y1 = x-kernel_size // 2, y-kernel_size // 2\n        x2, y2 = x + kernel_size // 2 + 1, y + kernel_size // 2 + 1\n\n        # Out of bounds offset\n        dx1, dy1, dx2, dy2 = 0, 0, 0, 0 \n        out_of_bounds = False\n        \n        # Following four ifs are used to determine whether the x and y of the two top corners are out of bounds\n        if x1 <0:\n            dx1 = abs(x1)\n            x1 = 0\n            out_of_bounds = True\n        if y1 <0:\n            dy1 = abs(y1)\n            y1 = 0\n            out_of_bounds = True\n        if x2> w:\n            dx2 = x2-w\n            x2 = w\n            out_of_bounds = True\n        if y2> h:\n            dy2 = y2-h\n            y2 = h\n            out_of_bounds = True\n\n        # If it is out of bounds, adjust the size of the Gaussian kernel\n        if out_of_bounds:\n            kernel_h = kernel_size-dy1-dy2\n            kernel_w = kernel_size-dx1-dx2\n\n            # Generate a Gaussian kernel of size (kernel_h, kernel_w)\n            H = np.multiply(cv2.getGaussianKernel(kernel_h, sigma), (cv2.getGaussianKernel(kernel_w, sigma)).T)\n        else:\n            # Generate a Gaussian kernel of size (15, 15)\n            H = np.multiply(cv2.getGaussianKernel(kernel_size, sigma), (cv2.getGaussianKernel(kernel_size, sigma)).T)\n\n        density_map[y1:y2, x1:x2] += H\n        \n    return density_map","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.087207Z","iopub.execute_input":"2022-03-29T18:23:14.08748Z","iopub.status.idle":"2022-03-29T18:23:14.100563Z","shell.execute_reply.started":"2022-03-29T18:23:14.087453Z","shell.execute_reply":"2022-03-29T18:23:14.09987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displays count of the number of people in each image in training dataset\n\nnum_images = train_dataset_size\npeople_count_train_images = []\n\nfor idx in range(num_images):\n    i = idx + 1\n\n    mat_img = loadmat(''.join((train_gt_path, 'GT_IMG_', str(i), '.mat')))\n    image_info = mat_img['image_info']\n    annPoints = image_info[0][0][0][0][0]\n    people_count_train_images.append(len(annPoints))\n\nprint(people_count_train_images)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.101818Z","iopub.execute_input":"2022-03-29T18:23:14.102191Z","iopub.status.idle":"2022-03-29T18:23:14.190241Z","shell.execute_reply.started":"2022-03-29T18:23:14.102156Z","shell.execute_reply":"2022-03-29T18:23:14.18949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images in which count of people is less than 200\ncnt_less_than_equal_to_200 = 0\nfor i in people_count_train_images:\n    if i <= 200:\n        cnt_less_than_equal_to_200 += 1\nprint(cnt_less_than_equal_to_200)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.191355Z","iopub.execute_input":"2022-03-29T18:23:14.191691Z","iopub.status.idle":"2022-03-29T18:23:14.197044Z","shell.execute_reply.started":"2022-03-29T18:23:14.191655Z","shell.execute_reply":"2022-03-29T18:23:14.196316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filter out images in which count of people less than 200\ncount_in_train_images = [count for count in people_count_train_images if count <= 200]\nprint(len(count_in_train_images))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.198143Z","iopub.execute_input":"2022-03-29T18:23:14.198873Z","iopub.status.idle":"2022-03-29T18:23:14.206454Z","shell.execute_reply.started":"2022-03-29T18:23:14.198839Z","shell.execute_reply":"2022-03-29T18:23:14.20564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizes the training dataset images\n\nfig,ax = plt.subplots(figsize=(5,5))\nax.plot(range(len(count_in_train_images)),count_in_train_images)\nax.legend()\nax.title.set_text('Number of people in Part B training images')\nax.set_xlabel('number of images')\nax.set_ylabel('number of people')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.207609Z","iopub.execute_input":"2022-03-29T18:23:14.208173Z","iopub.status.idle":"2022-03-29T18:23:14.436777Z","shell.execute_reply.started":"2022-03-29T18:23:14.20814Z","shell.execute_reply":"2022-03-29T18:23:14.436162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code saves the density map of training images as csv files\n\nnum_images = train_dataset_size\n# number of images for validation purpose\nnum_val = math.ceil(num_images * 0.1)  \n\nfor idx in range(num_images):\n    # remove images in which people count is greater than 200\n    if people_count_train_images[idx] > 200:\n        continue\n        \n    i = idx + 1\n    if i % 10 == 0:\n        print('Processing {}/{} files'.format(i, num_images))\n    \n    input_img_name = ''.join((train_images_path, 'IMG_', str(i), '.jpg'))\n    \n    # loading image and ground truth file\n    if os.path.isfile(input_img_name):\n        im = cv2.imread(input_img_name, 0)\n        mat_img = loadmat(''.join((train_gt_path, 'GT_IMG_', str(i), '.mat')))\n        image_info = mat_img['image_info']\n        # annotated head pixel coordinates\n        annPoints = image_info[0][0][0][0][0]\n        \n        # generate density map\n        im_density = gen_density_map(im, annPoints)\n        \n        # setting density map name and path and saving it\n        with open(''.join([train_gt_den_map_csv_path, str(i), '.csv']), 'w', newline='') as fout:\n            writer = csv.writer(fout)\n            writer.writerows(im_density)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:23:14.437782Z","iopub.execute_input":"2022-03-29T18:23:14.438158Z","iopub.status.idle":"2022-03-29T18:24:50.172942Z","shell.execute_reply.started":"2022-03-29T18:23:14.438123Z","shell.execute_reply":"2022-03-29T18:24:50.172179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting number of images to display in output\n\nnum_of_train_images_to_display = 5\nnum_of_test_images_to_display = 10","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:24:50.1741Z","iopub.execute_input":"2022-03-29T18:24:50.174518Z","iopub.status.idle":"2022-03-29T18:24:50.17886Z","shell.execute_reply.started":"2022-03-29T18:24:50.174479Z","shell.execute_reply":"2022-03-29T18:24:50.178205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading and shuffling training images\ntrain_image_files = [filename for filename in os.listdir(train_gt_den_map_csv_path)]\nrandom.shuffle(train_image_files)\n\nprint(len(train_image_files))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:24:50.180043Z","iopub.execute_input":"2022-03-29T18:24:50.180578Z","iopub.status.idle":"2022-03-29T18:24:50.189135Z","shell.execute_reply.started":"2022-03-29T18:24:50.180542Z","shell.execute_reply":"2022-03-29T18:24:50.188128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this code displays the generated density map for training images from annotated heads data in ground truth files\n\nfor idx in range(num_of_train_images_to_display):\n    i = int(train_image_files[idx].split('.')[0])\n    \n    # initializing a subplot of 1*2\n    f, axarr = plt.subplots(1, 2, figsize=(10,10))\n    \n    input_img_name = ''.join((train_images_path, 'IMG_', str(i), '.jpg'))\n    \n    # load and display image and density map\n    if os.path.isfile(input_img_name):\n        axarr[0].imshow(Image.open(input_img_name))\n\n        im_density = np.loadtxt(open(''.join([train_gt_den_map_csv_path, str(i), '.csv']), \"rb\"), delimiter=\",\")\n        axarr[1].imshow(im_density, interpolation='nearest')\n\n        # removing ticks from both axes\n        axarr[0].set_xticks([])\n        axarr[0].set_yticks([])\n        axarr[1].set_xticks([])\n        axarr[1].set_yticks([])\n        \n        # setting plot x and y labels\n        axarr[0].set_xlabel('original image')\n        axarr[1].set_xlabel('density map')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:24:50.190307Z","iopub.execute_input":"2022-03-29T18:24:50.19074Z","iopub.status.idle":"2022-03-29T18:24:53.840733Z","shell.execute_reply.started":"2022-03-29T18:24:50.190706Z","shell.execute_reply":"2022-03-29T18:24:53.840049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code saves the density map and cropped images of the patches of training and validation data\n\nnum_images = train_dataset_size\n# number of images for validation purpose\nnum_val = math.ceil(num_images * 0.1)\n\n# training and validation images count\nnew_train_images_cnt = 0\nnew_val_images_cnt = 0\n\nfor idx in range(num_images):\n    # remove images in which peopl count is greater than 200\n    if people_count_train_images[idx] > 200:\n        continue\n        \n    i = idx + 1\n    if i % 10 == 0:\n        print('Processing {}/{} files'.format(i, num_images))\n    \n    input_img_name = ''.join((train_images_path, 'IMG_', str(i), '.jpg'))\n\n    if os.path.isfile(input_img_name):\n        # load image\n        im = cv2.imread(input_img_name, 0)\n        \n        # load ground truth file\n        mat_img = loadmat(''.join((train_gt_path, 'GT_IMG_', str(i), '.mat')))\n        image_info = mat_img['image_info']\n        annPoints = image_info[0][0][0][0][0]\n      \n        im_density = gen_density_map(im, annPoints)\n        \n        # counting training and validation images\n        if (idx+1) < (num_images-num_val):\n            new_train_images_cnt += 1\n        else:\n            new_val_images_cnt += 1\n    \n        h, w = im.shape\n        # setting patch size to be (h/4, w/4)\n        patch_h, patch_w = int(h/4), int(w/4)\n\n        # extract patches data from image\n        j = 0\n        for l in range(4):\n            for k in range(4):\n                # calculating corner points of the patch to be cropped\n                x1 = k*patch_w\n                y1 = l*patch_h\n                x2 = (k+1)*patch_w\n                y2 = (l+1)*patch_h\n                j += 1\n                \n                # crop image and the density map for the patch\n                im_sampled = im[y1:y2, x1:x2]\n                im_density_sampled = im_density[y1:y2, x1:x2]\n\n                # setting patch unique name and path for image and density map and saving both of them\n                img_idx = ''.join((str(i), '_', str(j)))\n                path_img, path_den = (patches_path_train_images, patches_path_train_den_map) if (idx+1) < (num_images-num_val) else (patches_path_val_images, patches_path_val_den_map)\n                cv2.imwrite(''.join([path_img, img_idx, '.jpg']), im_sampled)\n                \n                with open(''.join([path_den, img_idx, '.csv']), 'w', newline='') as fout:\n                    writer = csv.writer(fout)\n                    writer.writerows(im_density_sampled)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:24:53.842148Z","iopub.execute_input":"2022-03-29T18:24:53.84249Z","iopub.status.idle":"2022-03-29T18:26:36.204611Z","shell.execute_reply.started":"2022-03-29T18:24:53.842456Z","shell.execute_reply":"2022-03-29T18:26:36.203961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting patches path for input data to MCNN model\n\ntrain_path = patches_path_train_images\ntrain_den_path = patches_path_train_den_map\nval_path = patches_path_val_images\nval_den_path = patches_path_val_den_map","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:26:36.217461Z","iopub.execute_input":"2022-03-29T18:26:36.217986Z","iopub.status.idle":"2022-03-29T18:26:36.224572Z","shell.execute_reply.started":"2022-03-29T18:26:36.217951Z","shell.execute_reply":"2022-03-29T18:26:36.223879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This class loads the training and validation data of the patches\n\nclass DataLoader(object):\n    def __init__(self, data_path, gt_path, shuffle=False, gt_downsample=False):\n         \n        # initialize path to input data\n        self.data_path = data_path\n        self.gt_path = gt_path\n        self.shuffle = shuffle\n        self.gt_downsample = gt_downsample\n        \n        # load files\n        self.data_files = [filename for filename in os.listdir(gt_path)]\n        self.num_samples = len(self.data_files)\n        self.blob_list = []\n\n        for fname in self.data_files:\n            # load image as grayscale\n            img = cv2.imread(os.path.join(self.data_path, os.path.splitext(fname)[0] +'.jpg'), 0)\n            img = img.astype(np.float32, copy=False)\n            ht = img.shape[0]\n            wd = img.shape[1]\n            \n            ht_1 = int((ht / 4) * 4)\n            wd_1 = int((wd / 4) * 4)\n            \n            # resizing and reshaping image to one dimension\n            img = cv2.resize(img, (wd_1, ht_1))\n            img = img.reshape((img.shape[0], img.shape[1], 1))\n            \n            # reading density map\n            den = pd.read_csv(os.path.join(self.gt_path, fname),\n                              header=None).values\n            den = den.astype(np.float32, copy=False)\n            if self.gt_downsample:\n                wd_1 = int(wd_1 / 4)\n                ht_1 = int(ht_1 / 4)\n            den = cv2.resize(den, (wd_1, ht_1))\n            den = den * ((wd * ht) / (wd_1 * ht_1))\n            den = den.reshape((den.shape[0], den.shape[1], 1))\n            \n            # creating object for patch data\n            blob = dict()\n            blob['data'] = img\n            blob['gt'] = den\n            blob['fname'] = fname\n            self.blob_list.append(blob)\n\n        if self.shuffle:\n            np.random.shuffle(self.blob_list)\n\n    # returning data in batches\n    def flow(self, batch_size=32):\n        loop_count = self.num_samples // batch_size\n        while True:\n            np.random.shuffle(self.blob_list)\n            for i in range(loop_count):\n                blobs = self.blob_list[i*batch_size: (i+1)*batch_size]\n                X_batch = np.array([blob['data'] for blob in blobs])\n                Y_batch = np.array([blob['gt'] for blob in blobs])\n                yield X_batch, Y_batch\n    \n    # returring whole data\n    def get_all(self):\n        X = np.array([blob['data'] for blob in self.blob_list])\n        Y = np.array([blob['gt'] for blob in self.blob_list])\n        return X, Y\n    \n    # iterate over data\n    def __iter__(self):\n        for blob in self.blob_list:\n            yield blob","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:26:36.225934Z","iopub.execute_input":"2022-03-29T18:26:36.226422Z","iopub.status.idle":"2022-03-29T18:26:36.258283Z","shell.execute_reply.started":"2022-03-29T18:26:36.226387Z","shell.execute_reply":"2022-03-29T18:26:36.257525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loads patches data for training and validation using DataLoader class\n\nprint('Loading data, wait a moment...')\ntrain_data_gen = DataLoader(train_path, train_den_path, shuffle=True, gt_downsample=True)\nval_data_gen = DataLoader(val_path, val_den_path, shuffle=False, gt_downsample=True)\n\nprint('done')\nprint(train_data_gen.num_samples)\nprint(val_data_gen.num_samples)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:26:36.259304Z","iopub.execute_input":"2022-03-29T18:26:36.259757Z","iopub.status.idle":"2022-03-29T18:28:00.426323Z","shell.execute_reply.started":"2022-03-29T18:26:36.259615Z","shell.execute_reply":"2022-03-29T18:28:00.424716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code for visualization of patches data\n\nct_gts = []\nxx=0\nfor blob in train_data_gen:\n    xx=xx+1\n    gt = blob['gt']\n    gt_count = np.sum(gt)\n    ct_gts.append(gt_count)\n\nprint(len(ct_gts))\n\n# plot to show number of people in each training patch\nfig,ax = plt.subplots(figsize=(5,5))\nax.plot(range(train_data_gen.num_samples),ct_gts,label='training')\nax.legend()\nax.set_xlabel('number of images')\nax.set_ylabel('number of people')\n\nct_gts2 = []\nxx=0\nfor blob2 in val_data_gen:\n    xx=xx+1\n    gt2 = blob2['gt']\n    gt_count2 = np.sum(gt2)\n    ct_gts2.append(gt_count2)\n\nprint(len(ct_gts2))\n\n# plot to show number of people in each validation patch\nfig2,ax2 = plt.subplots(figsize=(5,5))\nax2.plot(range(val_data_gen.num_samples),ct_gts2,label='validation')\nax2.legend()\nax2.set_xlabel('number of images')\nax2.set_ylabel('number of people')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:28:00.427783Z","iopub.execute_input":"2022-03-29T18:28:00.428061Z","iopub.status.idle":"2022-03-29T18:28:00.857438Z","shell.execute_reply.started":"2022-03-29T18:28:00.428026Z","shell.execute_reply":"2022-03-29T18:28:00.856669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining regression evaluation metrics\n\ndef mae(y_true, y_pred):\n    return K.abs(K.sum(y_true) - K.sum(y_pred))\n\ndef mse(y_true, y_pred):\n    return (K.sum(y_true) - K.sum(y_pred)) * (K.sum(y_true) - K.sum(y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:28:00.85875Z","iopub.execute_input":"2022-03-29T18:28:00.85903Z","iopub.status.idle":"2022-03-29T18:28:00.864149Z","shell.execute_reply.started":"2022-03-29T18:28:00.858987Z","shell.execute_reply":"2022-03-29T18:28:00.863282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the MCNN model\n\n# model uses convolution layer and max pooling layer with relu as activation function\ndef MCNN(input_shape=None):\n    inputs = Input(shape=input_shape)\n\n    # column 1\n    column_1 = Conv2D(16, (9, 9), padding='same', activation='relu')(inputs)\n    column_1 = MaxPooling2D(2)(column_1)\n    column_1 = (column_1)\n    column_1 = Conv2D(32, (7, 7), padding='same', activation='relu')(column_1)\n    column_1 = MaxPooling2D(2)(column_1)\n    column_1 = Conv2D(16, (7, 7), padding='same', activation='relu')(column_1)\n    column_1 = Conv2D(8, (7, 7), padding='same', activation='relu')(column_1)\n\n    # column 2\n    column_2 = Conv2D(20, (7, 7), padding='same', activation='relu')(inputs)\n    column_2 = MaxPooling2D(2)(column_2)\n    column_2 = (column_2)\n    column_2 = Conv2D(40, (5, 5), padding='same', activation='relu')(column_2)\n    column_2 = MaxPooling2D(2)(column_2)\n    column_2 = Conv2D(20, (5, 5), padding='same', activation='relu')(column_2)\n    column_2 = Conv2D(10, (5, 5), padding='same', activation='relu')(column_2)\n\n    # column 3\n    column_3 = Conv2D(24, (5, 5), padding='same', activation='relu')(inputs)\n    column_3 = MaxPooling2D(2)(column_3)\n    column_3 = (column_3)\n    column_3 = Conv2D(48, (3, 3), padding='same', activation='relu')(column_3)\n    column_3 = MaxPooling2D(2)(column_3)\n    column_3 = Conv2D(24, (3, 3), padding='same', activation='relu')(column_3)\n    column_3 = Conv2D(12, (3, 3), padding='same', activation='relu')(column_3)\n\n    # merge feature map of 3 columns in last dimension\n    merges = Concatenate(axis=-1)([column_1, column_2, column_3])\n    \n    # density map generation\n    density_map = Conv2D(1, (1, 1), padding='same')(merges)\n\n    model = Model(inputs=inputs, outputs=density_map)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:28:00.865712Z","iopub.execute_input":"2022-03-29T18:28:00.865981Z","iopub.status.idle":"2022-03-29T18:28:00.880622Z","shell.execute_reply.started":"2022-03-29T18:28:00.865948Z","shell.execute_reply":"2022-03-29T18:28:00.87984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting path to save trained model\n\ntrained_model_path = '../working/shanghaitech/trained_models/' + dataset_part + '/'\n\n# creating directory to store trained model\nfor i in [trained_model_path]:\n    if not os.path.exists(i):\n        os.makedirs(i)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:28:00.882003Z","iopub.execute_input":"2022-03-29T18:28:00.882316Z","iopub.status.idle":"2022-03-29T18:28:00.89164Z","shell.execute_reply.started":"2022-03-29T18:28:00.882282Z","shell.execute_reply":"2022-03-29T18:28:00.890946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initializing the MCNN model\n\ninput_shape = (None, None, 1)\nmodel = MCNN(input_shape)\n\n# setting model optimizers and loss parameters\nadam = Adam(learning_rate=1e-6)\nmodel.compile(loss='mse', optimizer=adam, metrics=[mae, mse])\n\nmodel_name = 'model1.h5'\n\n# using model checkpointing technique to save model whenever the model accuracy has improved\ncheckpointer_best_train = ModelCheckpoint(\n    filepath=trained_model_path + model_name,\n    monitor='loss', verbose=1, save_best_only=True, mode='min'\n)\n\ncallback_list = [checkpointer_best_train]\n\nprint('done prepare {} ...'.format(dataset_part))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:28:00.892712Z","iopub.execute_input":"2022-03-29T18:28:00.893035Z","iopub.status.idle":"2022-03-29T18:28:03.291172Z","shell.execute_reply.started":"2022-03-29T18:28:00.893001Z","shell.execute_reply":"2022-03-29T18:28:03.290493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the MCNN model \n\nprint (\"start train..........\")\nh = model.fit(train_data_gen.flow(1),\n                    steps_per_epoch=train_data_gen.num_samples // 1,\n                    validation_data=val_data_gen.flow(1),\n                    validation_steps=val_data_gen.num_samples // 1,\n                    batch_size=10,\n                    epochs=100,\n                    callbacks=callback_list,\n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T18:28:03.292397Z","iopub.execute_input":"2022-03-29T18:28:03.292656Z","iopub.status.idle":"2022-03-29T19:31:46.789023Z","shell.execute_reply.started":"2022-03-29T18:28:03.292621Z","shell.execute_reply":"2022-03-29T19:31:46.788195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the trained model\n\nimport tensorflow as tf\n\ntrained_model_path = '../working/shanghaitech/trained_models/' + dataset_part + '/' + model_name\nmodel = tf.keras.models.load_model(trained_model_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:46.81805Z","iopub.execute_input":"2022-03-29T19:31:46.818328Z","iopub.status.idle":"2022-03-29T19:31:47.029451Z","shell.execute_reply.started":"2022-03-29T19:31:46.818293Z","shell.execute_reply":"2022-03-29T19:31:47.028812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting path to test images directory\n\ntest_images_path = dataset_base_path + 'test_data/images/'\ntest_gt_path = dataset_base_path + 'test_data/ground-truth/'","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.030758Z","iopub.execute_input":"2022-03-29T19:31:47.031022Z","iopub.status.idle":"2022-03-29T19:31:47.034999Z","shell.execute_reply.started":"2022-03-29T19:31:47.030986Z","shell.execute_reply":"2022-03-29T19:31:47.03424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Outputs the count of number of people in each image in test dataset\n\n# test images sample size\ntest_dataset_size = 316\n\nnum_images = test_dataset_size\npeople_count_test_images = []\n\nfor idx in range(num_images):\n    i = idx + 1\n    \n    # load ground truth file\n    mat_img = loadmat(''.join((test_gt_path, 'GT_IMG_', str(i), '.mat')))\n    image_info = mat_img['image_info']\n    annPoints = image_info[0][0][0][0][0]\n    people_count_test_images.append(len(annPoints))\n\nprint(people_count_test_images)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.036429Z","iopub.execute_input":"2022-03-29T19:31:47.0367Z","iopub.status.idle":"2022-03-29T19:31:47.10705Z","shell.execute_reply.started":"2022-03-29T19:31:47.036665Z","shell.execute_reply":"2022-03-29T19:31:47.106273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  count test images that have people count less than equal to 200\ncnt_less_than_equal_to_200_test = 0\nfor i in people_count_test_images:\n    if i <= 200:\n        cnt_less_than_equal_to_200_test += 1\nprint(cnt_less_than_equal_to_200_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.108225Z","iopub.execute_input":"2022-03-29T19:31:47.108516Z","iopub.status.idle":"2022-03-29T19:31:47.113821Z","shell.execute_reply.started":"2022-03-29T19:31:47.108481Z","shell.execute_reply":"2022-03-29T19:31:47.113179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filtering out test images that has count less than equal to 200\ncount_in_test_images = [count for count in people_count_test_images if count <= 200]\nprint(len(count_in_test_images))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.11479Z","iopub.execute_input":"2022-03-29T19:31:47.115428Z","iopub.status.idle":"2022-03-29T19:31:47.122187Z","shell.execute_reply.started":"2022-03-29T19:31:47.115392Z","shell.execute_reply":"2022-03-29T19:31:47.121402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this code visualizes the count of people in test dataset\n\nfig,ax = plt.subplots(figsize=(5,5))\nax.plot(range(len(count_in_test_images)),count_in_test_images)\nax.legend()\nax.title.set_text('Number of people in test images')\nax.set_xlabel('number of images')\nax.set_ylabel('number of people')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.123674Z","iopub.execute_input":"2022-03-29T19:31:47.124278Z","iopub.status.idle":"2022-03-29T19:31:47.343513Z","shell.execute_reply.started":"2022-03-29T19:31:47.124242Z","shell.execute_reply":"2022-03-29T19:31:47.342892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting path to results directory\n\nresults_dir = '../working/shanghaitech/results/' + dataset_part + '/'\nheatmaps_dir = results_dir + 'den_map/'\ntxt_dir = results_dir + 'text/'\ntest_gt_den_map_csv_path = output_base_path + 'test_data/ground_truth_den_map_csv/'\n\n# creating result directories\nfor i in [results_dir, heatmaps_dir, txt_dir, test_gt_den_map_csv_path]:\n    if not os.path.exists(i):\n        os.makedirs(i)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.344902Z","iopub.execute_input":"2022-03-29T19:31:47.345347Z","iopub.status.idle":"2022-03-29T19:31:47.351815Z","shell.execute_reply.started":"2022-03-29T19:31:47.34531Z","shell.execute_reply":"2022-03-29T19:31:47.351202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code saves the density map of testing images as csv files\n\nnum_images = test_dataset_size\n\nfor idx in range(num_images):\n    # remove images in which people count is greater than 200\n    if people_count_test_images[idx] > 200:\n        continue\n        \n    i = idx + 1\n    if i % 10 == 0:\n        print('Processing {}/{} files'.format(i, num_images))\n    \n    input_img_name = ''.join((test_images_path, 'IMG_', str(i), '.jpg'))\n    \n    if os.path.isfile(input_img_name):\n        # load image\n        im = cv2.imread(input_img_name, 0)\n\n        mat_img = loadmat(''.join((test_gt_path, 'GT_IMG_', str(i), '.mat')))\n        image_info = mat_img['image_info']\n        annPoints = image_info[0][0][0][0][0]\n\n        # generate density map\n        im_density = gen_density_map(im, annPoints)\n\n        # setting density map name and path and saving it\n        with open(''.join([test_gt_den_map_csv_path, 'IMG_', str(i), '.csv']), 'w', newline='') as fout:\n            writer = csv.writer(fout)\n            writer.writerows(im_density)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:31:47.353358Z","iopub.execute_input":"2022-03-29T19:31:47.353641Z","iopub.status.idle":"2022-03-29T19:33:05.998538Z","shell.execute_reply.started":"2022-03-29T19:31:47.353606Z","shell.execute_reply":"2022-03-29T19:33:05.997856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load testing sample\nprint('Loading data, wait a moment...')\ntest_data_loader = DataLoader(test_images_path, test_gt_den_map_csv_path, shuffle=False, gt_downsample=True)\nprint(test_data_loader.num_samples)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:33:06.002639Z","iopub.execute_input":"2022-03-29T19:33:06.004826Z","iopub.status.idle":"2022-03-29T19:33:45.175187Z","shell.execute_reply.started":"2022-03-29T19:33:06.004784Z","shell.execute_reply":"2022-03-29T19:33:45.174331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction of people in images using trained model\n\nprint('Testing {} ...'.format(dataset_part))\n\n# variable to store mean absolute error and mean squared error\nmae = 0.0\nmse = 0.0\nu=0\n\n# dictionary to store predictions\npredictions = {}\nct_preds = []\n# list to store actual values\nct_gts = []\nxx=0\nfor blob in test_data_loader:\n    xx=xx+1\n    img = blob['data']\n    gt = blob['gt']\n    \n    # predicting density map and people count from trained model for testing images\n    pred = model.predict(np.expand_dims(img, axis=0))\n    gt_count = np.sum(gt)\n    pred_count = np.sum(pred)\n    ct_preds.append(pred_count)\n    ct_gts.append(gt_count)\n    \n    image_no = blob['fname'].split('.')[0][4:]\n    predictions[image_no] = pred_count\n  \n    # calculating absolute error and squared error \n    mae += abs(gt_count - pred_count)\n    mse += ((gt_count - pred_count) * (gt_count - pred_count))\n    \n    # create and save heatmap\n    pred = np.squeeze(pred)  # shape(1, h, w, 1) -> shape(h, w)\n    \n    #save_heatmap\n    with open(''.join([heatmaps_dir, 'IMG_', str(image_no), '.csv']), 'w', newline='') as fout:\n          writer = csv.writer(fout)\n          writer.writerows(pred)\n        \n    # save results\n    print('<{}> {:.2f} -- {:.2f}\\n'.format(blob['fname'].split('.')[0], gt_count, pred_count))\n    with open(txt_dir + 'predictions.txt', 'a') as f:\n        line = '<{}> {:.2f} -- {:.2f}\\n'.format(blob['fname'].split('.')[0], gt_count, pred_count)\n        f.write(line)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:33:45.176815Z","iopub.execute_input":"2022-03-29T19:33:45.177331Z","iopub.status.idle":"2022-03-29T19:34:14.080856Z","shell.execute_reply.started":"2022-03-29T19:33:45.177186Z","shell.execute_reply":"2022-03-29T19:34:14.080081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and shuffle test images\ntest_image_files = [filename for filename in os.listdir(test_gt_den_map_csv_path)]\nrandom.shuffle(test_image_files)\nprint(len(test_image_files))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:34:14.082286Z","iopub.execute_input":"2022-03-29T19:34:14.082733Z","iopub.status.idle":"2022-03-29T19:34:14.089656Z","shell.execute_reply.started":"2022-03-29T19:34:14.082684Z","shell.execute_reply":"2022-03-29T19:34:14.08889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# displays the original image, ground truth and predicted density map for test images\n\nfor idx in range(num_of_test_images_to_display):\n    i = int(test_image_files[idx].split('.')[0][4:])\n    \n    # initializing a subplot of size 1*3\n    f, axarr = plt.subplots(1, 3, figsize=(10,10))\n    \n    input_img_name = ''.join((test_images_path, 'IMG_', str(i), '.jpg'))\n    \n    if os.path.isfile(input_img_name):\n        axarr[0].imshow(Image.open(input_img_name))\n\n        im_density = np.loadtxt(open(''.join([test_gt_den_map_csv_path, 'IMG_', str(i), '.csv']), \"rb\"), delimiter=\",\")\n        axarr[1].imshow(im_density, interpolation='nearest')\n\n        im_density = np.loadtxt(open(''.join([heatmaps_dir, 'IMG_', str(i), '.csv']), \"rb\"), delimiter=\",\")\n        axarr[2].imshow(im_density, interpolation='nearest')\n\n        # removing ticks from both axes\n        axarr[0].set_xticks([])\n        axarr[0].set_yticks([])\n        axarr[1].set_xticks([])\n        axarr[1].set_yticks([])\n        axarr[2].set_xticks([])\n        axarr[2].set_yticks([])\n        \n        # setting x-label\n        axarr[0].set_xlabel('original image')\n        axarr[1].set_xlabel('ground truth')\n        axarr[2].set_xlabel('predicted density map')\n        \n        # setting plot title\n        axarr[1].title.set_text('original count: ' + str(people_count_test_images[i-1]))\n        axarr[2].title.set_text('predicted count: ' + str(int(predictions[str(i)])))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:34:14.091036Z","iopub.execute_input":"2022-03-29T19:34:14.091401Z","iopub.status.idle":"2022-03-29T19:34:22.508344Z","shell.execute_reply.started":"2022-03-29T19:34:14.091343Z","shell.execute_reply":"2022-03-29T19:34:22.507686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating mean absolute error and mean squared error\navg_mae = mae / test_data_loader.num_samples\navg_mse = np.sqrt(mse / test_data_loader.num_samples)\nprint(\"mae - \", avg_mae)\nprint(\"mse - \", avg_mse)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:34:22.509788Z","iopub.execute_input":"2022-03-29T19:34:22.510294Z","iopub.status.idle":"2022-03-29T19:34:22.516943Z","shell.execute_reply.started":"2022-03-29T19:34:22.510254Z","shell.execute_reply":"2022-03-29T19:34:22.516068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing model predictions with actual values\nplt.plot(ct_preds, 'r>')\nplt.plot(ct_gts, 'b+')\nplt.legend(['prediction', 'ground truth'])\nplt.xlabel('number of image')\nplt.ylabel('number of people')\nplt.title('Prediction vs Ground Truth')\nplt.show()\n\nerror = np.array(ct_preds) - np.array(ct_gts)\nplt.plot(error)\nplt.xlabel('number of image')\nplt.ylabel('difference in count of people')\nplt.title('Prediction Count - Ground Truth Count')\nplt.show()\n\nidx_max_error = np.argsort(np.abs(error))[::-1]\nprint('MEAN = {}, MAE = {}, MSE = {}'.format(\n    str(round(np.mean(error), 3)),\n    str(round(np.mean(np.abs(error)), 3)),\n    str(round(np.sqrt(np.mean(np.abs(error)*np.abs(error))), 3)),\n))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T19:34:22.518704Z","iopub.execute_input":"2022-03-29T19:34:22.519268Z","iopub.status.idle":"2022-03-29T19:34:22.889238Z","shell.execute_reply.started":"2022-03-29T19:34:22.51919Z","shell.execute_reply":"2022-03-29T19:34:22.888527Z"},"trusted":true},"execution_count":null,"outputs":[]}]}